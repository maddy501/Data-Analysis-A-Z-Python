{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_cleaning_2_pynb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbDzTfxkvg73"
      },
      "source": [
        "# **Filtering || Removing Missing Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeGAo6l8vp33"
      },
      "source": [
        "**Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEjGC5IUM8NE"
      },
      "source": [
        "# Find values of acct_cur that are equal to 'euro'\n",
        "acct_eu = banking['acct_cur'] == 'euro'\n",
        "\n",
        "# Convert acct_amount where it is in euro to dollars\n",
        "banking.loc[acct_eu, 'acct_amount'] = banking.loc[acct_eu, 'acct_amount'] * 1.1\n",
        "\n",
        "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
        "banking.loc[acct_eu, 'acct_cur'] = 'dollar'\n",
        "\n",
        "# Print unique values of acct_cur\n",
        "assert banking['acct_cur'].unique() == 'dollar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54qYcg9NgR0"
      },
      "source": [
        "# Print the header of account_opened\n",
        "print(banking['account_opened'].head())\n",
        "\n",
        "# Convert account_opened to datetime\n",
        "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
        "                                           # Infer datetime format\n",
        "                                           infer_datetime_format = True,\n",
        "                                           # Return missing value for error\n",
        "                                           errors = 'coerce') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE1e4uCXNn5l"
      },
      "source": [
        "# Print the header of account_opend\n",
        "print(banking['account_opened'].head())\n",
        "\n",
        "# Convert account_opened to datetime\n",
        "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
        "                                           # Infer datetime format\n",
        "                                           infer_datetime_format = True,\n",
        "                                           # Return missing value for error\n",
        "                                           errors = 'coerce') \n",
        "\n",
        "# Get year of account opened\n",
        "banking['acct_year'] = banking['account_opened'].dt.strftime('%Y')\n",
        "\n",
        "# Print acct_year\n",
        "print(banking['acct_year'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxNpGDDxOM0T"
      },
      "source": [
        "# Store fund columns to sum against\n",
        "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']\n",
        "\n",
        "# Find rows where fund_columns row sum == inv_amount\n",
        "inv_equ = banking[fund_columns].sum(axis=1) == banking['inv_amount']\n",
        "\n",
        "# Store consistent and inconsistent data\n",
        "consistent_inv = banking[inv_equ]\n",
        "inconsistent_inv = banking[~inv_equ]\n",
        "\n",
        "# Store consistent and inconsistent data\n",
        "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAwNLg9YwZM3"
      },
      "source": [
        "categories = ['asian', 'american', 'italian']\n",
        "\n",
        "# For each correct cuisine_type in categories\n",
        "for cuisine in categories:\n",
        "  # Find matches in cuisine_type of restaurants\n",
        "  matches = process.extract(cuisine, restaurants['cuisine_type'], \n",
        "                 limit =restaurants['cuisine_type'].shape[0])\n",
        "  \n",
        "  # For each possible_match with similarity score >= 80\n",
        "  for possible_match in matches:\n",
        "    if possible_match[1] >= 80:\n",
        "      # Find matching cuisine type\n",
        "      matching_cuisine = restaurants['cuisine_type'] == possible_match[0]\n",
        "      restaurants.loc[matching_cuisine, 'cuisine_type'] = cuisine\n",
        "\n",
        "# Print unique values to confirm mapping\n",
        "print(restaurants['cuisine_type'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llzj1J9xwbAK"
      },
      "source": [
        "# Create a comparison object\n",
        "comp_cl = recordlinkage.Compare()\n",
        "\n",
        "\n",
        "# Create a comparison object\n",
        "comp_cl = recordlinkage.Compare()\n",
        "\n",
        "# Find exact matches on city, cuisine_types \n",
        "comp_cl.exact('city', 'city', label='city')\n",
        "comp_cl.exact('cuisine_type', 'cuisine_type', label='cuisine_type')\n",
        "\n",
        "# Find similar matches of rest_name\n",
        "comp_cl.string('rest_name', 'rest_name', label='name', threshold = 0.8) \n",
        "\n",
        "\n",
        "\n",
        "# Create a comparison object\n",
        "comp_cl = recordlinkage.Compare()\n",
        "\n",
        "# Find exact matches on city, cuisine_types - \n",
        "comp_cl.exact('city', 'city', label='city')\n",
        "comp_cl.exact('cuisine_type', 'cuisine_type', label='cuisine_type')\n",
        "\n",
        "# Find similar matches of rest_name\n",
        "comp_cl.string('rest_name', 'rest_name', label='name', threshold = 0.8) \n",
        "\n",
        "# Get potential matches and print\n",
        "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new)\n",
        "print(potential_matches)\n",
        "\n",
        "\n",
        "potential_matches[potential_matches.sum(axis = 1) >= n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfJ1L8AXwhmX"
      },
      "source": [
        "# Isolate potential matches with row sum >=3\n",
        "matches = potential_matches[potential_matches.sum(axis=1) >= 3]\n",
        "\n",
        "# Get values of second column index of matches\n",
        "matching_indices = matches.index.get_level_values(1)\n",
        "\n",
        "# Subset restaurants_new based on non-duplicate values\n",
        "non_dup = restaurants_new[~restaurants_new.index.isin(matching_indices)]\n",
        "\n",
        "# Append non_dup to restaurants\n",
        "full_restaurants = restaurants.append(non_dup)\n",
        "print(full_restaurants)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDLb1FX1vtc6"
      },
      "source": [
        "**Remove Missing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO2OzcGlOS42"
      },
      "source": [
        "# Print number of missing values in banking\n",
        "print(banking.isna().sum())\n",
        "\n",
        "# Visualize missingness matrix\n",
        "msno.matrix(banking)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQL396OtOiyP"
      },
      "source": [
        "# Drop missing values of cust_id\n",
        "banking_fullid = banking.dropna(subset = ['cust_id'])\n",
        "\n",
        "# Compute estimated acct_amount\n",
        "acct_imp = banking_fullid[\"inv_amount\"]*5\n",
        "\n",
        "# Impute missing acct_amount with corresponding acct_imp\n",
        "banking_imputed = banking_fullid.fillna({'acct_amount':acct_imp})\n",
        "#banking_imputed = banking_fullid[\"acct_amount\"].fillna(acct_imp)\n",
        "\n",
        "# Print number of missing values\n",
        "print(banking_imputed.isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}